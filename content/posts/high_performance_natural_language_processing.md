+++
title = "High Performance Natural Language Processing"
author = ["Jethro Kuan"]
draft = false
+++

We need high-performance [natural language processing]({{<relref "nlp.md" >}}) to scale up NLP systems in
production.

There are several approaches to achieving speeding up NLP systems.

## [Knowledge Distillation]({{< relref "knowledge_distillation" >}}) {#knowledge-distillation--knowledge-distillation-dot-md}

### <span class="org-todo todo TODO">TODO</span> DistillBert {#distillbert}

### <span class="org-todo todo TODO">TODO</span> MobileBert {#mobilebert}

## [Making Transformer Models Efficient]({{<relref "making_transformer_models_efficient.md" >}}) {#making-transformer-models-efficient--making-transformer-models-efficient-dot-md}

## Pruning {#pruning}

Pruning removes "unimportant" weights from a network.
E.g. Prune based on second-order derivatives: "Optimal Brain Damage" and "Optimal Brain Surgeon"

### <span class="org-todo todo TODO">TODO</span> [Lottery Ticket Hypothesis]({{< relref "lottery_ticket_hypothesis" >}}) in Transformer (NO_ITEM_DATA:brixSuccessfullyApplyingStabilized2020) {#lottery-ticket-hypothesis--lottery-ticket-hypothesis-dot-md--in-transformer--no-item-data-brixsuccessfullyapplyingstabilized2020}

## Bibliography {#bibliography}

NO_ITEM_DATA:brixSuccessfullyApplyingStabilized2020
