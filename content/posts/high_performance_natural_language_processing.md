+++
title = "High Performance Natural Language Processing"
author = ["Jethro Kuan"]
draft = false
+++

We need high-performance [natural language processing]({{<relref "nlp.md#" >}}) to scale up NLP systems in
production.

There are several approaches to achieving speeding up NLP systems.


## [Knowledge Distillation]({{<relref "knowledge_distillation.md#" >}}) {#knowledge-distillation--knowledge-distillation-dot-md}


### <span class="org-todo todo TODO">TODO</span> DistillBert {#distillbert}


### <span class="org-todo todo TODO">TODO</span> MobileBert {#mobilebert}


## [Making Transformer Models Efficient]({{<relref "transformer_models.md#" >}}) {#making-transformer-models-efficient--transformer-models-dot-md}


## Pruning {#pruning}

Pruning removes "unimportant" weights from a network.
E.g. Prune based on second-order derivatives: "Optimal Brain Damage" and "Optimal Brain Surgeon"


### <span class="org-todo todo TODO">TODO</span> [Lottery Ticket Hypothesis]({{<relref "lottery_ticket_hypothesis.md#" >}}) in Transformer (NO\_ITEM\_DATA:brixSuccessfullyApplyingStabilized2020) {#lottery-ticket-hypothesis--lottery-ticket-hypothesis-dot-md--in-transformer--no-item-data-brixsuccessfullyapplyingstabilized2020}


## Bibliography {#bibliography}

NO\_ITEM\_DATA:brixSuccessfullyApplyingStabilized2020