+++
title = "Human Behaviour As Optimal Control"
author = ["Jethro Kuan"]
draft = false
+++

Does [Reinforcement Learning ‚≠ê]({{<relref "reinforcement_learning.md" >}}) and [Optimal Control]({{<relref "optimal_control.md" >}}) provide a
reasonable model of human behaviour? Is there a better explanation?

For example, is the gait of a human being optimizing for a certain
objective?

If we assume that the policy maximizes the expectation of total
reward under some given dynamics, can we learn the human reward
function from the data?

We can model sub-optimal behaviour using techniques from graphical
models ([Control As Inference]({{<relref "control_as_inference.md" >}})), and use this framework to derive new
"soft" RL algorithms (keywords: soft optimality).

## Resources {#resources}

- [CS285 Fa19 10/16/19 - YouTube](https://www.youtube.com/watch?v=Pei6G8%5F3r8I&list=PLkFD6%5F40KJIwhWJpGazJ9VSj9CFMkb79A&index=13)
