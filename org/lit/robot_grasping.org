:PROPERTIES:
:ID:       91baf5d1-80c6-42f6-b2bb-d16a1a277095
:END:
#+setupfile:./hugo_setup.org
#+hugo_slug: robot_grasping
#+title: Robot Grasping

Humans are able to perform dexterous manipulation of everyday, unseen objects
with their limbs. Yet, it remains a challenge for robots to perform grasping and
manipulation of objects.

A typical robot grasp detection system can consist of 3 components.

- [[file:object_localization.org][Object localization]] :: determining the target object's location
- [[file:object_pose_estimation.org][Object Pose Estimation]] :: obtaining a target object's 6D pose in the scene
- [[file:grasp_estimation.org][Grasp Estimation]] :: Estimating the grasp pose in the camera's coordinate frame

* Challenges

1. The robot needs to adapt to changes in the environment.
2. The robot is susceptible to noise and errors in the environment, in control,
   in perception, and perturbations to the robot itself.

* Grasping Approaches

- Dexterous manipulation :: manipulation with fingers
- Enveloping grasps :: formed by wrapping both fingers and palm around object

  Enveloping grasps have superior stability. Grasping Simulators such as
  (GraspIt!) have been made available for theoretical research.

* Closed-loop Grasping

Execution time is the primary reason why grasping systems remain open-loop.
However, closed-loop control via visual feedback is desirable because they are
able to adapt to dynamic environments, and require less precise position control
or camera calibration. [[id:0570cdd6-baad-4709-b3f9-6edeceac90f6][morrison_closing_2018: Closing the Loop for Robotic
Grasping: A Real-time, Generative Grasp Synthesis Approach]] uses neural network
to synthesize a grasp quality image in real-time to achieve closed-loop
grasping.
